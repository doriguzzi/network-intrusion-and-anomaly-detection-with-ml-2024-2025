{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression \n",
    "In this lab we train a Logistic Regression model with synthetic data for a binary classification problem. Given a labelled dataset of synthetic data, we train a Logistic regression model to find a linear decision boundary between two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Machine Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# Create a synthetic dataset with two classes that are linearly separable\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_classes=2, n_informative=2, n_redundant=0,\n",
    "                           n_clusters_per_class=1, class_sep=2.0, random_state=SEED)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', edgecolors='k')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Synthetic Dataset with Two Linearly Separable Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the logistic regression model using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learned coefficients (weights and bias) from the trained model\n",
    "weights, bias = model.layers[0].get_weights()\n",
    "coefficients = [weights[0][0], weights[1][0], bias[0]]\n",
    "\n",
    "# Print the learned coefficients\n",
    "print(\"Decision boundary: \" +  str(bias[0]) + \" + \" + str(weights[0][0]) + \"*X1\" + \" + \" + str(weights[1][0]) + \"*X2\")\n",
    "\n",
    "# Calculate slope and intercept for the decision boundary line\n",
    "slope = -coefficients[0] / coefficients[1]\n",
    "intercept = -coefficients[2] / coefficients[1]\n",
    "\n",
    "# Plot the data points and decision boundary line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', cmap='viridis')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "\n",
    "# Plot the decision boundary line\n",
    "x_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\n",
    "y_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n",
    "plt.plot([x_min, x_max], [slope * x_min + intercept, slope * x_max + intercept], color='red', linestyle='--')\n",
    "\n",
    "plt.title('Decision Boundary as a Single Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for plotting the hyperplane in 3D space\n",
    "xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 50),\n",
    "                     np.linspace(X[:, 1].min(), X[:, 1].max(), 50))\n",
    "zz = (-coefficients[0] * xx - coefficients[1] * yy - coefficients[2]) / coefficients[2]\n",
    "\n",
    "\n",
    "# Plot the hyperplane in 3D space\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xx, yy, zz, color='c', alpha=0.5)\n",
    "ax.scatter(X[:, 0], X[:, 1], y, c=y, edgecolors='k', cmap=plt.cm.Set1)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Output (before the sigmoid function)')\n",
    "ax.set_title('Hyperplane in 3D Space')\n",
    "\n",
    "ax.view_init(elev=5, azim=180)  # Elev: Elevation (up/down), Azim: Azimuthal (rotation around the z axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(model.predict(X_test, batch_size=32) > 0.5)\n",
    "\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learned coefficients (weights and bias) from the trained model\n",
    "weights, bias = model.layers[0].get_weights()\n",
    "coefficients = [weights[0][0], weights[1][0], bias[0]]\n",
    "\n",
    "# Print the learned coefficients\n",
    "print(\"Decision boundary: \" +  str(bias[0]) + \" + \" + str(weights[0][0]) + \"*X1\" + \" + \" + str(weights[1][0]) + \"*X2\")\n",
    "\n",
    "# Calculate slope and intercept for the decision boundary line\n",
    "slope = -coefficients[0] / coefficients[1]\n",
    "intercept = -coefficients[2] / coefficients[1]\n",
    "\n",
    "# Plot the data points and decision boundary line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolors='k', cmap='viridis')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "\n",
    "# Plot the decision boundary line\n",
    "x_min, x_max = X_test[:, 0].min(), X_test[:, 0].max()\n",
    "y_min, y_max = X_test[:, 1].min(), X_test[:, 1].max()\n",
    "plt.plot([x_min, x_max], [slope * x_min + intercept, slope * x_max + intercept], color='red', linestyle='--')\n",
    "\n",
    "plt.title('Decision Boundary as a Single Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with polynomial features\n",
    "Logistic regression can be extended to handle polynomial features by incorporating polynomial terms into the feature space. This technique is known as Polynomial Logistic Regression. It allows the logistic regression model to capture nonlinear relationships between the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Machine Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "SEED  = 1\n",
    "\n",
    "# Create a synthetic dataset with two classes that are not linearly separable\n",
    "X, y = make_circles(n_samples=1000, noise=0.1, factor=0.3, random_state=SEED)\n",
    "\n",
    "# Add polynomial features to the data\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Synthetic Dataset with Non Linearly Separable Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the logistic regression model using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=X_poly.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary as a single curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "h = .02  # Step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Transform meshgrid points into polynomial features\n",
    "xx_poly = poly.transform(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Predict probabilities for each point on the meshgrid\n",
    "Z = model.predict(xx_poly)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the contour line representing the decision boundary (where probability is 0.5)\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='black')\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='viridis')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Neural Network: Decision Boundary with Polynomial Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(model.predict(X_test, batch_size=32) > 0.5)\n",
    "\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
